import yfinance as yf
import pandas as pd
from tabulate import tabulate
import argparse
from datetime import datetime, timedelta
import pytz

# Define Sectors and Top 5 Constituents
SECTORS = {
    "XLK": ["AAPL", "NVDA", "MSFT", "AVGO", "CRM"],
    "XLV": ["LLY", "UNH", "JNJ", "ABBV", "MRK"],
    "XLF": ["BRK-B", "JPM", "V", "MA", "GS"],
    "XLY": ["AMZN", "TSLA", "HD", "MCD", "NKE"],
    "XLC": ["META", "GOOGL", "GOOG", "NFLX", "DIS"],
    "XLI": ["CAT", "GE", "UNP", "HON", "RTX"],
    "XLP": ["PG", "COST", "KO", "PEP", "WMT"],
    "XLE": ["XOM", "CVX", "COP", "SLB", "EOG"],
    "XLRE": ["PLD", "AMT", "EQIX", "WELL", "PSA"],
    "XLU": ["NEE", "SO", "DUK", "CEG", "SRE"],
    "XLB": ["LIN", "APD", "SHW", "CTVA", "FCX"]
}

SECTOR_NAMES = {
    "XLK": "æƒ…å ±æŠ€è¡“", "XLV": "ãƒ˜ãƒ«ã‚¹ã‚±ã‚¢", "XLF": "é‡‘è", "XLY": "ä¸€èˆ¬æ¶ˆè²»è²¡",
    "XLP": "ç”Ÿæ´»å¿…éœ€å“", "XLC": "é€šä¿¡", "XLE": "ã‚¨ãƒãƒ«ã‚®ãƒ¼", "XLI": "è³‡æœ¬è²¡",
    "XLB": "ç´ æ", "XLU": "å…¬å…±äº‹æ¥­", "XLRE": "ä¸å‹•ç”£",
    "QQQ": "NAS100", "SPY": "S&P500", "DIA": "NYãƒ€ã‚¦"
}

# New Thematic Sectors (Representative ETF as Key)
THEME_SECTORS = {
    "ITB": ["HD", "LOW", "SHW", "DHI", "LEN", "PHM", "NVR", "LII", "TOL", "BLD"], # Housing/Construction
    "FINX": ["MSFT", "NVDA", "INTU", "FIS", "COIN", "PYPL", "SOFI", "PANW", "CRWD", "AFRM"], # Fintech/Cloud
    "GDX": ["NEM", "AEM", "FCX", "SCCO", "ALB", "GOLD", "WPM", "NUE", "PAAS", "MP"], # Gold/Materials (Using GDX as proxy)
    "XOP": ["XOM", "CVX", "EOG", "SLB", "BKR", "HAL", "MPC", "PSX", "WMB", "KMI"], # Energy/Oil (Using XOP as proxy)
    
    "ICLN": ["TSLA", "NEE", "ENPH", "FSLR", "ALB", "CCJ", "FCX", "SEDG", "OKLO", "UEC"], # Clean Energy
    "PAVE": ["PLD", "EQIX", "AMT", "UNP", "CSX", "UPS", "FDX", "ETN", "AMZN", "CAT"], # Infra/Transport
    "SOXX": ["NVDA", "MSFT", "AVGO", "TSM", "AMD", "ASML", "PANW", "CRWD", "SNOW", "ADBE"], # Semis/AI
    "IBB": ["AMGN", "ABBV", "REGN", "VRTX", "ISRG", "SYK", "MDT", "BSX", "ABT", "JNJ"], # Bio/Health
    "ITA": ["LMT", "RTX", "BA", "GD", "JPM", "BAC", "GS", "COST", "WMT", "UNP"], # Defense/Aero/Etc
    "KWEB": ["PDD", "BABA", "YUMC", "TAL", "VIPS", "TME", "BZ", "EA", "TTWO", "RBLX"] # China/Games
}

THEME_NAMES = {
    "ITB": "ä½å®…ãƒ»å»ºè¨­ãƒ»ä¸å‹•ç”£",
    "FINX": "ãƒ•ã‚£ãƒ³ãƒ†ãƒƒã‚¯ãƒ»ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ»æ±ºæ¸ˆ",
    "GDX": "é‡‘ãƒ»éŠ€ãƒ»é‡‘å±ãƒ»ç´ æ",
    "XOP": "ã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒ»æ¢é‰±ãƒ»ä¸­æµ",
    "ICLN": "ã‚¯ãƒªãƒ¼ãƒ³ã‚¨ãƒãƒ»æ°´ç´ ãƒ»ã‚¦ãƒ©ãƒ³",
    "PAVE": "ã‚¤ãƒ³ãƒ•ãƒ©ãƒ»é‹è¼¸ãƒ»ãƒ‡ãƒ¼ã‚¿ã‚»ãƒ³ã‚¿ãƒ¼",
    "SOXX": "åŠå°ä½“ãƒ»AIãƒ»ã‚µã‚¤ãƒãƒ¼",
    "IBB": "ãƒã‚¤ã‚ªãƒ»åŒ»ç™‚ãƒ»ãƒ˜ãƒ«ã‚¹",
    "ITA": "é˜²è¡›ãƒ»èˆªç©ºå®‡å®™ãƒ»è¤‡åˆ",
    "KWEB": "ä¸­å›½ãƒ»ã‚²ãƒ¼ãƒ ãƒ»ã‚¨ãƒ³ã‚¿ãƒ¡"
}

INDICES = ["QQQ", "SPY", "DIA"]
MACRO_TICKERS = ["GLD", "FXY", "UUP", "TLT"]
MACRO_NAMES = {
    "GLD": "ã‚´ãƒ¼ãƒ«ãƒ‰ (Gold)",
    "FXY": "æ—¥æœ¬å†† (Yen)",
    "UUP": "ãƒ‰ãƒ«æŒ‡æ•° (USD)",
    "TLT": "ç±³å›½å‚µ20å¹´è¶… (Bonds)"
}

def fetch_data(start_str=None, end_str=None):
    all_tickers = []
    
    # Standard Sectors
    for sector, stocks in SECTORS.items():
        all_tickers.append(sector)
        all_tickers.extend(stocks)
        
    # Thematic Sectors
    for sector, stocks in THEME_SECTORS.items():
        all_tickers.append(sector)
        all_tickers.extend(stocks)
        
    all_tickers.extend(INDICES)
    all_tickers.extend(MACRO_TICKERS)
    
    all_tickers = list(set(all_tickers))
    
    # Determine interval and period based on start_date
    interval = "15m"
    use_period = False
    
    if start_str:
        try:
            start_dt = pd.to_datetime(start_str)
            days_ago = (datetime.now() - start_dt).days
            if days_ago > 59:
                interval = "1d"
                print(f"Start date is {days_ago} days ago. Switching to daily interval (1d).")
        except:
            pass
    else:
        use_period = True

    print(f"Fetching data for {len(all_tickers)} tickers (Interval: {interval})...")
    
    try:
        if use_period:
            data = yf.download(all_tickers, period="1mo", interval="15m", group_by='ticker', auto_adjust=True, threads=True)
        else:
            s_dt = pd.to_datetime(start_str)
            e_dt = pd.to_datetime(end_str) + timedelta(days=1)
            
            data = yf.download(all_tickers, start=s_dt.strftime("%Y-%m-%d"), end=e_dt.strftime("%Y-%m-%d"), interval=interval, group_by='ticker', auto_adjust=True, threads=True)
            
        return data
    except Exception as e:
        print(f"Error fetching data: {e}")
        return None

def filter_data_by_date(df, start_date_str=None, end_date_str=None):
    if df is None or df.empty: return df
    filtered = df.copy()
    is_tz_aware = filtered.index.tzinfo is not None
    timezone = pytz.timezone("America/New_York")
    
    if start_date_str:
        try:
            start_dt = pd.to_datetime(start_date_str)
            if is_tz_aware and start_dt.tzinfo is None:
                start_dt = timezone.localize(start_dt)
            filtered = filtered[filtered.index >= start_dt]
        except: pass

    if end_date_str:
        try:
            end_dt = pd.to_datetime(end_date_str)
            if is_tz_aware and end_dt.tzinfo is None:
                end_dt = timezone.localize(end_dt)
            filtered = filtered[filtered.index <= end_dt]
        except: pass
    return filtered

def calculate_mdd_rf(df):
    """
    Calculate Maximum Drawdown (MDD) and Recovery Factor (RF).
    MDD: Max percentage drop from peak to trough within the period.
    RF: Net Return / |MDD|.
    """
    if df.empty: return 0.0, 0.0

    # Calculate High water mark
    roll_max = df['High'].cummax()
    # Drawdown = (Low - HighWaterMark) / HighWaterMark
    daily_dd = (df['Low'] - roll_max) / roll_max
    mdd = daily_dd.min() # This is a negative float, e.g. -0.05 for -5%
    
    # Return for the period
    start_p = df.iloc[0]['Open']
    end_p = df.iloc[-1]['Close']
    ret = (end_p - start_p) / start_p # Float, e.g. 0.10 for 10%

    # RF Calculation
    rf = 0.0
    if mdd == 0:
        if ret > 0: rf = 99.99 # Infinite recovery (no drawdown)
        else: rf = 0.0 # No return, no drawdown
    else:
        rf = ret / abs(mdd)
        
    return mdd * 100, rf # Return MDD as percentage (negative) and RF (ratio)

def analyze_last_day_shape(df, prev_close=None):
    if df.empty: return 0, "N/A", 0, 0, 0, 0, ""
    last_date = df.index[-1].date()
    # Handle duplicate indices if any, or strictly filter by date
    last_day_df = df[df.index.date == last_date]
    if last_day_df.empty: return 0, "N/A", 0, 0, 0, 0, ""
        
    open_p = last_day_df.iloc[0]['Open']
    close_p = last_day_df.iloc[-1]['Close']
    high_p = last_day_df['High'].max()
    low_p = last_day_df['Low'].min()
    
    # Use Prev Close for % change if available, else Open (Intraday)
    base_p = prev_close if prev_close is not None else open_p
    move_pct = (close_p - base_p) / base_p * 100
    
    range_len = high_p - low_p
    date_str = last_date.strftime("%m/%d")
    if range_len == 0: return 0, "Doji", move_pct, open_p, high_p, close_p, date_str
    
    close_pos = (close_p - low_p) / range_len
    
    desc = ""
    score = 0 # -2 to +2
    
    if close_pos > 0.8:
        desc = "é«˜å€¤å¼•ã‘ (Strong)"
        score = 2
    elif close_pos < 0.2:
        desc = "å®‰å€¤å¼•ã‘ (Weak)"
        score = -2
    elif move_pct > 0.3:
        desc = "é™½ç·š (Pos)"
        score = 1
    elif move_pct < -0.3:
        desc = "é™°ç·š (Neg)"
        score = -1
    else:
        desc = "ä¿ã¡åˆã„ (Neut)"
        score = 0
        
    return score, desc, move_pct, open_p, high_p, close_p, date_str

def generate_three_scenarios(trend_return, last_score, last_move):
    """
    Generate 3 distinct scenarios: Good (Bull), Avg (Base), Bad (Bear).
    Returns: Grade, Scenarios Dict
    """
    grade = "æ™®"
    scenarios = {
        "Good": "",
        "Avg": "",
        "Bad": ""
    }
    
    # 1. Strong Uptrend (>3%)
    if trend_return > 3.0:
        if last_score >= 1: # Uptrend + Strong
            grade = "è‰¯"
            scenarios["Avg"] = "ä¸Šæ˜‡ãƒˆãƒ¬ãƒ³ãƒ‰ç¶™ç¶šã€‚é«˜å€¤æ›´æ–°ã‚’è©¦ã™å‹•ãã€‚"
            scenarios["Good"] = "å‹¢ã„ãŒåŠ é€Ÿã—ã€å¸¯çŠ¶ã«ä¸Šæ˜‡ã™ã‚‹ (Band Walk)ã€‚"
            scenarios["Bad"] = "åˆ©ç›Šç¢ºå®šå£²ã‚Šã§ä¸€æ™‚çš„ãªèª¿æ•´ãŒå…¥ã‚‹ã€‚"
        elif last_score <= -1: # Uptrend + Weak
            grade = "æ™®"
            scenarios["Avg"] = "ä¸Šæ˜‡ä¸€æœã€‚èª¿æ•´å±€é¢å…¥ã‚Šã‚’ç¤ºå”†ã€‚"
            scenarios["Good"] = "æŠ¼ã—ç›®ã‚’å½¢æˆã—ã€å†åº¦ä¸Šæ˜‡ã«è»¢ã˜ã‚‹ã€‚"
            scenarios["Bad"] = "ç›´è¿‘å®‰å€¤ã‚’å‰²ã‚Šè¾¼ã¿ã€ãƒˆãƒ¬ãƒ³ãƒ‰ãŒå´©ã‚Œã‚‹ã€‚"
        else: # Uptrend + Neutral
            grade = "è‰¯"
            scenarios["Avg"] = "ä¸Šæ˜‡ãƒˆãƒ¬ãƒ³ãƒ‰ç¶™ç¶šã€‚æŠ¼ã—ç›®å¾…ã¡ã€‚"
            scenarios["Good"] = "ã‚‚ã¿åˆã„ã‚’ä¸Šæ”¾ã‚Œã—ã€å†åŠ é€Ÿã™ã‚‹ã€‚"
            scenarios["Bad"] = "èª¿æ•´ãŒé•·å¼•ãã€ãƒ¬ãƒ³ã‚¸ç›¸å ´ã¸ç§»è¡Œã™ã‚‹ã€‚"
            
    # 2. Strong Downtrend (<-3%)
    elif trend_return < -3.0:
        if last_score >= 1: # Downtrend + Strong
            grade = "æ™®"
            scenarios["Avg"] = "è‡ªå¾‹åç™ºã€‚ã‚·ãƒ§ãƒ¼ãƒˆã‚«ãƒãƒ¼å„ªå‹¢ã€‚"
            scenarios["Good"] = "åº•æ‰“ã¡ã‚’ç¢ºèªã—ã€æœ¬æ ¼çš„ãªãƒªãƒã‚¦ãƒ³ãƒ‰ã¸ã€‚"
            scenarios["Bad"] = "ã‚ãã¾ã§ä¸€æ™‚çš„ãªåç™ºã§ã€å†åº¦å®‰å€¤ã‚’æ›´æ–°ã€‚"
        elif last_score <= -1: # Downtrend + Weak
            grade = "æ‚ª"
            scenarios["Avg"] = "ä¸‹è½ç¶™ç¶šã€‚å®‰å€¤æ¨¡ç´¢ã®å±•é–‹ã€‚"
            scenarios["Good"] = "ã‚»ãƒªãƒ³ã‚°ã‚¯ãƒ©ã‚¤ãƒãƒƒã‚¯ã‚¹ã‚’è¿ãˆã€æ€¥åç™ºã™ã‚‹ã€‚"
            scenarios["Bad"] = "å£²ã‚ŠãŒå£²ã‚Šã‚’å‘¼ã³ã€ãƒ‘ãƒ‹ãƒƒã‚¯çš„ãªä¸‹ã’ã«ãªã‚‹ã€‚"
        else:
            grade = "æ‚ª"
            scenarios["Avg"] = "ä¸‹è½ãƒˆãƒ¬ãƒ³ãƒ‰ç¶™ç¶šã€‚æˆ»ã‚Šå£²ã‚Šè­¦æˆ’ã€‚"
            scenarios["Good"] = "ä¸‹ã’æ­¢ã¾ã‚Šã€åº•å›ºã‚ã®å‹•ãã¸ã€‚"
            scenarios["Bad"] = "ã‚¸ãƒªã‚¸ãƒªã¨ä¸‹å€¤ã‚’åˆ‡ã‚Šä¸‹ã’ã‚‹ã€‚"
            
    # 3. Range / Neutral
    else:
        if last_score >= 1: # Range + Strong
            grade = "è‰¯"
            scenarios["Avg"] = "ãƒ¬ãƒ³ã‚¸ä¸Šé™ã¸ã®ãƒˆãƒ©ã‚¤ã€‚"
            scenarios["Good"] = "ãƒ¬ãƒ³ã‚¸ã‚’ä¸ŠæŠœã‘ã€æ–°ãŸãªä¸Šæ˜‡ãƒˆãƒ¬ãƒ³ãƒ‰ã¸ã€‚"
            scenarios["Bad"] = "ãƒ¬ãƒ³ã‚¸ä¸Šé™ã§è·³ã­è¿”ã•ã‚Œã€å†åº¦ä¿ã¡åˆã„ã¸ã€‚"
        elif last_score <= -1: # Range + Weak
            grade = "æ‚ª"
            scenarios["Avg"] = "ãƒ¬ãƒ³ã‚¸ä¸‹é™ã¸ã®ãƒˆãƒ©ã‚¤ã€‚"
            scenarios["Good"] = "ä¸‹é™ã§ã‚µãƒãƒ¼ãƒˆã•ã‚Œã€åç™ºã™ã‚‹ã€‚"
            scenarios["Bad"] = "ãƒ¬ãƒ³ã‚¸ã‚’ä¸‹æŠœã‘ã€ä¸‹è½ãƒˆãƒ¬ãƒ³ãƒ‰å…¥ã‚Šã™ã‚‹ã€‚"
        else:
            grade = "æ™®"
            scenarios["Avg"] = "æ–¹å‘æ„Ÿãªã—ã€‚æ§˜å­è¦‹ã€‚"
            scenarios["Good"] = "ææ–™å‡ºç¾ã§å‹•æ„ã¥ãã€‚"
            scenarios["Bad"] = "å‡ºæ¥é«˜ç´°ã‚Šã€é–‘æ•£ç›¸å ´ã¨ãªã‚‹ã€‚"
            
    return grade, scenarios

def analyze_ticker(ticker, data, start_arg, end_arg):
    try:
        if ticker not in data.columns.levels[0]: return None
        raw = data[ticker].dropna()
    except KeyError:
        return None
    except Exception as e:
        # Fallback for flat index 
        if ticker in data.columns:
            raw = data[ticker].dropna()
        else:
            return None
    df = filter_data_by_date(raw, start_arg, end_arg)
    if df.empty: return None
    
    start_p = df.iloc[0]['Open']
    end_p = df.iloc[-1]['Close']
    high_p = df['High'].max()
    
    # Convert timestamps to JST for display
    jst = pytz.timezone('Asia/Tokyo')
    try:
        first_ts = df.index[0]
        last_ts = df.index[-1]
        
        if first_ts.tzinfo is not None:
            first_jst = first_ts.astimezone(jst)
            last_jst = last_ts.astimezone(jst)
            start_date_str = first_jst.strftime("%m/%d %H:%M")
            end_date_str = last_jst.strftime("%m/%d %H:%M") + " JST"
        else:
            # For daily data (no timezone info), just show date
            start_date_str = first_ts.strftime("%m/%d")
            end_date_str = last_ts.strftime("%m/%d")
    except:
        start_date_str = "N/A"
        end_date_str = "N/A"
    
    ret = (end_p - start_p) / start_p * 100
    
    # Calculate Previous Close for accurate Daily % Change
    prev_close = None
    try:
        current_date = df.index[-1].date()
        past_data = raw[raw.index.date < current_date]
        if not past_data.empty:
            prev_close = past_data.iloc[-1]['Close']
    except Exception:
        pass

    score, desc, move, l_open, l_high, l_close, l_date = analyze_last_day_shape(df, prev_close)
    
    grade, scenarios = generate_three_scenarios(ret, score, move)
    
    mdd, rf = calculate_mdd_rf(df)
    
    return {
        "Ticker": ticker,
        "Start": start_p,
        "High": high_p,
        "End": end_p,
        "Return": ret,
        "DateRange": f"{start_date_str} - {end_date_str}",
        "LastScore": score,
        "LastDesc": desc,
        "LastMove": move,
        "LastOpen": l_open,
        "LastHigh": l_high,
        "LastClose": l_close,
        "LastDate": l_date,
        "Grade": grade,
        "Scenarios": scenarios,
        "MDD": mdd,
        "RF": rf
    }

def analyze_sector(sector_ticker, holdings, data, start_arg=None, end_arg=None):
    # Use names from either standard or theme dict
    sec_name = SECTOR_NAMES.get(sector_ticker, THEME_NAMES.get(sector_ticker, sector_ticker))

    s_res = analyze_ticker(sector_ticker, data, start_arg, end_arg)
    if not s_res: return None
    
    stats = []
    
    for stock in holdings:
        st_res = analyze_ticker(stock, data, start_arg, end_arg)
        if not st_res: continue
        
        rel_trend = st_res['Return'] - s_res['Return']
        role = "NEUTRAL"
        reason = ""
        
        if rel_trend > 0:
            role = "ENGINE (ç‰½å¼•)"
            if st_res['LastScore'] >= 0:
                reason = f"ãƒˆãƒ¬ãƒ³ãƒ‰ç‰½å¼• (+{st_res['Return']:.1f}%)"
            else:
                reason = f"ãƒˆãƒ¬ãƒ³ãƒ‰ã¯å¼·ã„ãŒã€ç›´è¿‘ã§å¤±é€Ÿ ({st_res['LastDesc']})"
        else:
            role = "BRAKE (é‡çŸ³)"
            if st_res['LastScore'] > 0:
                reason = f"å‡ºé…ã‚Œã ãŒã€ç›´è¿‘ã¯è²·ã‚ã‚Œã¦ã„ã‚‹ ({st_res['LastDesc']})"
            else:
                reason = f"ãƒˆãƒ¬ãƒ³ãƒ‰ã‚‚ç›´è¿‘ã‚‚å¼±ã„ ({st_res['LastDesc']})"
                
        st_res['Role'] = role
        st_res['Reason'] = reason
        stats.append(st_res)

    stats_df = pd.DataFrame(stats)
    if not stats_df.empty:
        stats_df = stats_df.sort_values("Return", ascending=False)
        
    engine_count = len([s for s in stats if "ENGINE" in s['Role']])
    total_count = len(stats)
    
    quality = "æ™®é€š (Mixed)"
    if total_count > 0:
        ratio = engine_count / total_count
        if ratio >= 0.8: 
            quality = "å¥å…¨ãªåºƒãŒã‚Š (Healthy)"
        elif ratio <= 0.2: 
            quality = "ä¸€éƒ¨ã¸ã®é€ƒé¿ (Selective)"
        elif ratio > 0.5:
            quality = "ã‚„ã‚„åºƒã„ (Broad)"
        else:
            quality = "é¸åˆ¥è‰²ã‚ã‚Š (Mixed)"
    
    return {
        "sector": sector_ticker,
        "name": sec_name,
        "return": s_res['Return'],
        "start_p": s_res['Start'],
        "end_p": s_res['End'],
        "date_range": s_res['DateRange'],
        "last_desc": s_res['LastDesc'],
        "last_move": s_res['LastMove'],
        "last_date": s_res['LastDate'],
        "grade": s_res['Grade'],
        "quality": quality,
        "scenarios": s_res['Scenarios'],
        "stats": stats_df,
        "MDD": s_res['MDD'],
        "RF": s_res['RF']
    }

def generate_narrative_report(results, index_results, macro_results, theme_results, start_dt_str, end_dt_str):
    analyzed_range = f"{start_dt_str} ã€œ {end_dt_str}"
    if index_results:
        analyzed_range = index_results[0]['DateRange'] 

    report = []
    report.append("ã€å¤©æ‰æŠ•è³‡å®¶ãƒ¬ãƒãƒ¼ãƒˆã€‘")
    report.append(f"åˆ†ææœŸé–“: {analyzed_range}\n")
    
    # 1. Indices
    report.append("### â‘  å…¨ä½“è¦³ (Indices)")
    for idx_res in index_results:
        idx = idx_res['Ticker']
        name = SECTOR_NAMES.get(idx, idx)
        
        report.append(f"**{name} ({idx})**: {idx_res['Grade']}")
        report.append(f"  Price: {idx_res['Start']:.2f} -> {idx_res['End']:.2f} ({idx_res['Return']:+.2f}%) [{idx_res['DateRange']}]")
        report.append(f"  ğŸ“Š **ãƒªã‚«ãƒãƒªãƒ¼ãƒ»ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼ (RF): {idx_res['RF']:.2f}** | **æœ€å¤§ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³ (MDD): {idx_res['MDD']:.1f}%**")
        report.append(f"  ç›´è¿‘: {idx_res['LastDesc']} ({idx_res['LastMove']:+.1f}%) [{idx_res['LastDate']}]")
        
        # Drivers/Draggers Logic (Simplified for standard sectors)
        related_sectors = []
        if idx == "QQQ": related_sectors = ["XLK", "XLC", "XLY"]
        elif idx == "DIA": related_sectors = ["XLI", "XLF", "XLV"]
        else: related_sectors = ["XLK", "XLF", "XLV", "XLY", "XLI", "XLE"]
        
        drivers = []
        draggers = []
        
        for sec_ticker in related_sectors:
            if sec_ticker in results:
                sec_ret = results[sec_ticker]['return']
                sec_name = results[sec_ticker]['name']
                if sec_ret > idx_res['Return'] + 0.5:
                    drivers.append(f"- {sec_name}: {sec_ret:+.1f}%")
                elif sec_ret < idx_res['Return'] - 0.5:
                    draggers.append(f"- {sec_name}: {sec_ret:+.1f}%")
                    
        if drivers:
            report.append("ğŸ”¥ **Engine (ç‰½å¼•)**:")
            report.extend(drivers)
        if draggers: 
            report.append("ğŸ§Š **Brake (é‡çŸ³)**:")
            report.extend(draggers)
        report.append("")

    report.append("="*40 + "\n")
    
    # 2. Sector Analysis (Standard)
    sorted_secs = sorted(results.values(), key=lambda x: x['return'], reverse=True)
    winner = sorted_secs[0]
    loser = sorted_secs[-1]

    # Macro Conclusion
    risk_on_score = 0
    if "XLK" in results and "XLY" in results:
        risk_on_avg = (results["XLK"]["return"] + results["XLY"]["return"]) / 2
        risk_off_avg = 0
        count = 0
        if "XLU" in results: 
            risk_off_avg += results["XLU"]["return"]
            count += 1
        if "XLP" in results:
            risk_off_avg += results["XLP"]["return"]
            count += 1
        
        if count > 0:
            risk_off_avg /= count
            if risk_on_avg > risk_off_avg + 1.0:
                risk_on_score = 1 # Risk On
            elif risk_on_avg < risk_off_avg - 1.0:
                risk_on_score = -1 # Risk Off
    
    flow_desc = ""
    if risk_on_score == 1:
        flow_desc = "æˆé•·æ ªã¸ã®è³‡é‡‘å›å¸°ãŒè¦‹ã‚‰ã‚Œã€å¸‚å ´å¿ƒç†ã¯ã€Œãƒªã‚¹ã‚¯é¸å¥½ (Risk On)ã€ã§ã™ã€‚"
    elif risk_on_score == -1:
        flow_desc = "ãƒ‡ã‚£ãƒ•ã‚§ãƒ³ã‚·ãƒ–ã‚»ã‚¯ã‚¿ãƒ¼ã¸ã®é€ƒé¿ãŒè¦‹ã‚‰ã‚Œã€å¸‚å ´å¿ƒç†ã¯ã€Œãƒªã‚¹ã‚¯å›é¿ (Risk Off)ã€ã§ã™ã€‚"
    else:
        flow_desc = "ã‚»ã‚¯ã‚¿ãƒ¼é–“ã®å¾ªç’°è‰²ãŒå¼·ãã€æ–¹å‘æ„Ÿã‚’æ¢ã‚‹å±•é–‹ã§ã™ã€‚"

    report.append("### â‘¡ ãƒã‚¯ãƒ­çµè«–: è³‡é‡‘æµå‹•")
    report.append(f"è³‡é‡‘ã¯**ã€Œ{loser['name']}ã€ã‹ã‚‰ã€Œ{winner['name']}ã€ã¸**ã‚·ãƒ•ãƒˆã—ã¦ã„ã¾ã™ã€‚")
    report.append(f"ã€çœŸå®Ÿã®çœ¼ã€‘ {flow_desc}")
    report.append(f"å‹è€…({winner['name']})ã¯{winner['quality']}ãªè²·ã„ãŒå…¥ã£ã¦ãŠã‚Šã€æ•—è€…({loser['name']})ã¯è³‡é‡‘æµå‡ºãŒé®®æ˜ã§ã™ã€‚")
    report.append("\n" + "-"*20 + "\n")

    # Standard Sectors
    for res in sorted_secs:
        _append_sector_details(report, res)

    # 3. Thematic Sectors Section
    report.append("### â‘¢ ãƒ†ãƒ¼ãƒåˆ¥ãƒ»æ³¨ç›®ã‚»ã‚¯ã‚¿ãƒ¼åˆ†æ (New Themes)")
    report.append("ä¼çµ±çš„ã‚»ã‚¯ã‚¿ãƒ¼ã«åŠ ãˆã€æ³¨ç›®åº¦ã®é«˜ã„10ã®ãƒ†ãƒ¼ãƒã‚’åˆ†æã—ã¾ã™ã€‚\n")
    
    sorted_themes = sorted(theme_results.values(), key=lambda x: x['return'], reverse=True)
    for res in sorted_themes:
        _append_sector_details(report, res)

    # 4. Rankings Section (Combined?)
    # User asked for "Existing things kept as is", so standard rankings first?
    # Or maybe combine them? 
    # Let's keep existing Rankings as "Sector Ranking" (Original 11)
    # And maybe add a "Theme Ranking"? 
    # Or just mix them? 
    # For now, I will keep standard rankings as requested "Existing things kept", 
    # and maybe append Theme rankings. Or mix if user didn't specify. 
    # "Existing ... kept as is". So I will keep the original ranking section for original sectors.
    
    report.append("### â‘£ ãƒªã‚«ãƒãƒªãƒ¼ãƒ»ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼ (RF) ãƒ©ãƒ³ã‚­ãƒ³ã‚° (Standard 11)")
    report.append("ã€Œãƒªã‚¹ã‚¯ã‚ãŸã‚Šã®ãƒªã‚¿ãƒ¼ãƒ³åŠ¹ç‡ã€ã‚’æ¯”è¼ƒã—ã¾ã™ã€‚æ•°å€¤ãŒé«˜ã„ã»ã©å„ªç§€ã§ã™ã€‚\n")
    
    # Sector Ranking
    sorted_rf_sectors = sorted(results.values(), key=lambda x: x['RF'], reverse=True)
    report.append("ã€ã‚»ã‚¯ã‚¿ãƒ¼åˆ¥ RF ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã€‘")
    rank_str_list = []
    medals = ["ğŸ¥‡", "ğŸ¥ˆ", "ğŸ¥‰"]
    for i, res in enumerate(sorted_rf_sectors):
        rank_icon = medals[i] if i < 3 else f"{i+1}."
        rank_str_list.append(f"{rank_icon} **{res['name']} ({res['sector']})**: RF {res['RF']:.2f} (Return: {res['return']:+.1f}% / MDD: {res['MDD']:.1f}%)")
    report.append(" ".join(rank_str_list))
    report.append("")
    
    # Stock Ranking (Standard)
    all_stocks = []
    for res in results.values():
        if not res['stats'].empty:
            for _, row in res['stats'].iterrows():
                all_stocks.append(row)
    
    sorted_stocks_rf = sorted(all_stocks, key=lambda x: x['RF'], reverse=True)
    report.append("ã€éŠ˜æŸ„åˆ¥ RF ãƒ©ãƒ³ã‚­ãƒ³ã‚° (Standard Top 10)ã€‘")
    top_str_list = []
    for i, row in enumerate(sorted_stocks_rf[:10]):
        rank_icon = medals[i] if i < 3 else f"{i+1}."
        top_str_list.append(f"{rank_icon} **{row['Ticker']}**: RF {row['RF']:.2f} (Return: {row['Return']:+.1f}% / MDD: {row['MDD']:.1f}%)")
    report.append(" ".join(top_str_list))
    report.append("\n" + "="*40 + "\n")

    # Theme Rankings
    report.append("### â‘¤ ãƒ†ãƒ¼ãƒåˆ¥ RF ãƒ©ãƒ³ã‚­ãƒ³ã‚° (New)")
    
    # Theme Sector Ranking
    sorted_rf_themes = sorted(theme_results.values(), key=lambda x: x['RF'], reverse=True)
    report.append("ã€ãƒ†ãƒ¼ãƒåˆ¥ RF ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã€‘")
    rank_str_list = []
    for i, res in enumerate(sorted_rf_themes):
        rank_icon = medals[i] if i < 3 else f"{i+1}."
        rank_str_list.append(f"{rank_icon} **{res['name']} ({res['sector']})**: RF {res['RF']:.2f} (Return: {res['return']:+.1f}% / MDD: {res['MDD']:.1f}%)")
    report.append(" ".join(rank_str_list))
    report.append("")

    # Theme Stock Ranking
    all_theme_stocks = []
    for res in theme_results.values():
        if not res['stats'].empty:
            for _, row in res['stats'].iterrows():
                all_theme_stocks.append(row)
    
    sorted_theme_stocks_rf = sorted(all_theme_stocks, key=lambda x: x['RF'], reverse=True)
    report.append("ã€ãƒ†ãƒ¼ãƒéŠ˜æŸ„åˆ¥ RF ãƒ©ãƒ³ã‚­ãƒ³ã‚° (Theme Top 10)ã€‘")
    top_str_list = []
    for i, row in enumerate(sorted_theme_stocks_rf[:10]):
        rank_icon = medals[i] if i < 3 else f"{i+1}."
        top_str_list.append(f"{rank_icon} **{row['Ticker']}**: RF {row['RF']:.2f} (Return: {row['Return']:+.1f}% / MDD: {row['MDD']:.1f}%)")
    report.append(" ".join(top_str_list))
    
    report.append("\n" + "="*40 + "\n")

    # 4. Macro Section (Renumbered to 6)
    report.append("### â‘¥ æ³¨ç›®ãƒã‚¯ãƒ­æŒ‡æ¨™ (Macro)")
    for res in macro_results:
        m_ticker = res['Ticker']
        m_name = MACRO_NAMES.get(m_ticker, m_ticker)
        report.append(f"**{m_name} ({m_ticker})**: {res['Return']:+.2f}%")
        report.append(f"  Price: {res['Start']:.2f} -> {res['End']:.2f} [{res['DateRange']}]")
        report.append(f"  ç›´è¿‘: {res['LastDesc']} ({res['LastMove']:+.2f}%) [{res['LastDate']}]")
        report.append(f"  RF: {res['RF']:.2f} | MDD: {res['MDD']:.1f}%")
        report.append("")
    
    return "\n".join(report)

def _append_sector_details(report, res):
    sec_name = res['name']
    ticker = res['sector']
    stats = res['stats']
    
    engines = stats[stats['Role'].str.contains('ENGINE')]
    brakes = stats[stats['Role'].str.contains('BRAKE')]
    
    report.append(f"## {sec_name} ({ticker})")
    report.append(f"**åˆ¤å®š**: {res['grade']}")
    report.append(f"**è³‡é‡‘ã®è³ªã®åˆ¤å®š**: {res['quality']}")
    
    report.append(f"**Price**: ${res['start_p']:.2f} -> ${res['end_p']:.2f} ({res['return']:+.2f}%) [{res['date_range']}]")
    report.append(f"ğŸ“Š **ãƒªã‚«ãƒãƒªãƒ¼ãƒ»ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼ (RF): {res['RF']:.2f}** | **æœ€å¤§ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³ (MDD): {res['MDD']:.1f}%**")
    report.append(f"**ç›´è¿‘**: {res['last_desc']} [{res['last_date']}]")
    
    if not engines.empty:
        report.append("ğŸ”¥ **Engine (ç‰½å¼•)**:")
        for _, row in engines.iterrows():
            trend_str = f"Trend: {row['Start']:.2f}->{row['High']:.2f}->{row['End']:.2f} ({row['Return']:+.1f}%) [{row['DateRange']}] (å§‹å€¤->é«˜å€¤->çµ‚å€¤) **[RF:{row['RF']:.2f}]**"
            last_str = f"Last: {row['LastOpen']:.2f}->{row['LastHigh']:.2f}->{row['LastClose']:.2f} ({row['LastMove']:+.1f}%) [{row['LastDate']}] (å§‹å€¤->é«˜å€¤->çµ‚å€¤)"
            report.append(f"- {row['Ticker']}: {trend_str} / {last_str} -> {row['Reason']}")
    
    if not brakes.empty:
        report.append("ğŸ§Š **Brake (é‡çŸ³)**:")
        for _, row in brakes.iterrows():
            trend_str = f"Trend: {row['Start']:.2f}->{row['High']:.2f}->{row['End']:.2f} ({row['Return']:+.1f}%) [{row['DateRange']}] (å§‹å€¤->é«˜å€¤->çµ‚å€¤) **[RF:{row['RF']:.2f}]**"
            last_str = f"Last: {row['LastOpen']:.2f}->{row['LastHigh']:.2f}->{row['LastClose']:.2f} ({row['LastMove']:+.1f}%) [{row['LastDate']}] (å§‹å€¤->é«˜å€¤->çµ‚å€¤)"
            report.append(f"- {row['Ticker']}: {trend_str} / {last_str} -> {row['Reason']}")
    
    report.append("\n" + "-"*20 + "\n")

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--start', type=str)
    parser.add_argument('--end', type=str)
    parser.add_argument('--days', type=int, default=14)
    args = parser.parse_args()

    jst = pytz.timezone('Asia/Tokyo')
    end_dt = datetime.now(jst)
    
    if args.end: end_dt = pd.to_datetime(args.end)
    start_dt = end_dt - timedelta(days=args.days)
    if args.start: start_dt = pd.to_datetime(args.start)
        
    start_str = start_dt.strftime("%Y-%m-%d")
    end_str = end_dt.strftime("%Y-%m-%d")
    
    print(f"Analyzing {start_str} to {end_str}...")
    
    data = fetch_data(start_str, end_str)
    if data is None: return

    index_results = []
    for idx in INDICES:
        res = analyze_ticker(idx, data, start_str, end_str)
        if res: index_results.append(res)

    macro_results = []
    for m in MACRO_TICKERS:
        res = analyze_ticker(m, data, start_str, end_str)
        if res: macro_results.append(res)

    results = {}
    for sector, holdings in SECTORS.items():
        res = analyze_sector(sector, holdings, data, start_str, end_str)
        if res: results[sector] = res
        
    theme_results = {}
    for sector, holdings in THEME_SECTORS.items():
        res = analyze_sector(sector, holdings, data, start_str, end_str)
        if res: theme_results[sector] = res

    if results or theme_results:
        report = generate_narrative_report(results, index_results, macro_results, theme_results, start_str, end_str)
        with open("analysis_output.txt", "w", encoding='utf-8') as f:
            f.write(report)
        print("Report Generated.")

if __name__ == "__main__":
    main()
